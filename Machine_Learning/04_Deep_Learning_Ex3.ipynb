{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1, 3)\n",
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# convolution example\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# image의 형태\n",
    "# 1장의 이미지는 3차원 형태의 데이터\n",
    "# (이미지의 개수, width, height, color) => 4차원 배열\n",
    "# (1,3,3,1)\n",
    "\n",
    "image= np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype = np.float32)\n",
    "\n",
    "# filter 준비 (Weight) \n",
    "# (width, height, color,필터의 개수) => 4차원 배열\n",
    "# (2,2,1,1)\n",
    "weight = np.array([[[[1,-5,10]],\n",
    "                   [[1,-5,10]]],\n",
    "                  [[[1,-5,10]],\n",
    "                   [[1,-5,10]]]])\n",
    "\n",
    "print(weight.shape)\n",
    "\n",
    "# stride 지정 (사실 2차원이면 되는데 image와 filter와의 행렬 연산 때문에 4차원으로 지정함)\n",
    "# (1, stride width, stride height, 1) => 4차원 배열 (0,3번의 1은 dummy 값)\n",
    "# stride = [1,1,1,1]\n",
    "\n",
    "# stride만큼 움직이며 filter와 convolution 계산하고 새로운 image( 결과 layer ) 즉, activation map이 return 됨\n",
    "# 해당 image의 특징을 가지고 있는 layer 생성됨\n",
    "# padding = \"VALID\" : 크기 줄어듦\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding = \"VALID\")\n",
    "print(conv2d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## CNN\n",
    "## MNIST 예제를 이용해서 하나의 이미지에 대한 Convolution Image 5개를 생성해보자\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",\n",
    "                                 one_hot=True)\n",
    "\n",
    "# 학습용 training image 중 2번째 image의 정보를 1차원 형태의 데이터로 얻어옴\n",
    "img = mnist.train.images[1]\n",
    "\n",
    "# 2차원 형태의 데이터로 변환\n",
    "img = img.reshape(28,28)\n",
    "plt.imshow(img, cmap= \"Greys\",interpolation =\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "# 해당 이미지를 convolution 이미지로 변형\n",
    "# 2차원 형태의 img를 4차원 형태의 img로 변환\n",
    "img = img.reshape(-1,28,28,1)\n",
    "\n",
    "# image 준비 완료\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# filter 준비\n",
    "# 5개의 filter를 이용, 2x2짜리 filter 이용\n",
    "# 결과 image 크기에 영향을 미치는 2가지 : filter의 가로, 세로와 stride의 개수\n",
    "# filter shape => (2,2,1,5)\n",
    "W = tf.Variable(tf.random_normal([2,2,1,5]), name = \"filter\")\n",
    "# padding = \"SAME\" : 원본 크기 유지\n",
    "\n",
    "conv2d = tf.nn.conv2d(img, W,strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "# convolution 결과\n",
    "# print(conv2d.shape) => (1, 14, 14, 5) : 14 x 14짜리 image가 5개 생성 됨\n",
    "\n",
    "# 새로 생성된 image를 plt를 이용해서 확인\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# np.swapaxes(배열,바꿀 index1, 바꿀 index2) : 배열의 축을 임의로 변경\n",
    "# (1, 14, 14, 5) => (5, 14, 14, 1)\n",
    "# 반복문을 돌려서 데이터를 편하게 추출하기 위해 축 변경\n",
    "conv2d = np.conv2d = np.swapaxes(conv2d,0,3)\n",
    "print(conv2d.shape) \n",
    "\n",
    "# plt.subplots() : 그림 여러개 그리는 함수\n",
    "\n",
    "# 1행 5열짜리 subplot 생성 : 5개의 그림을 1줄에 그림\n",
    "# fig : subplot 전체 지칭\n",
    "# axes[0]: subplot 시작 ~ fig.axes[4] : subplot 끝 \n",
    "fig,axes = plt.subplots(1,5)\n",
    "\n",
    "for idx, item in enumerate(conv2d):\n",
    "    axes[idx].imshow(item.reshape(14,14),cmap=\"Greys\") # 3차원 배열을 2차원 배열로 변환\n",
    "plt.show()\n",
    "\n",
    "# convolution한 5개의 image(크기가 작아지고 다양해진 image)를 가지고 학습하기 때문에 학습이 더 잘 됨\n",
    "\n",
    "# Convolution만 하면 값 & 크기가 커지기 때문에         => 입력 데이터가 커짐, 시간 오래 걸림\n",
    "# relu 함수를 취해서 0~1.xx의 범위 내로 값을 줄여주고\n",
    "# Pooling(Sampling)으로 크기를 줄이고 특징을 살려줌 \n",
    "\n",
    "# Convolution을 너무 많이 하면 특징이 흐려지기 때문에 적당히!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 7, 7, 64)\n",
      "Wall time: 840 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## MNIST with CNN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# 0. 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 1. Data Loading & Data 정제\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)\n",
    "\n",
    "# 2. placeholder 설정\n",
    "X = tf.placeholder(shape = [None,784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None,10], dtype = tf.float32)\n",
    "drop_rate = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "# 3. Convolution \n",
    "# 3-1. Convolution layer 1\n",
    "x_img = tf.reshape(X, [-1,28,28,1])\n",
    "W1 = tf.Variable(tf.random_normal([2,2,1,32]), name= \"filter1\")\n",
    "\n",
    "L1 = tf.nn.conv2d(x_img, W1, strides=[1,2,2,1],padding = \"SAME\")\n",
    "print(L1.shape) # => (?, 14, 14, 32)\n",
    "L1 = tf.nn.relu(L1)\n",
    "# tf.nn.max_pool(대상Layer, ksize = kernel size [dummy,행,열,dummy], strides = [dummy,행,열,dummy], padding )\n",
    "L1 = tf.nn.max_pool(L1, ksize= [1,2,2,1], strides = [1,2,2,1], padding = \"SAME\")\n",
    "print(L1.shape) # => (?, 7, 7, 32)\n",
    "\n",
    "# convolution한 결과 : 28 x 28의 원본 이미지 1장이 7 x 7 convolution 된 이미지 32장으로 바뀜\n",
    "\n",
    "# 3-2. Convolution layer 2\n",
    "\n",
    "# L1.shape = (?, 14, 14, 32)의 3번 index 값과 tf.random_normal([3,3,32,32])의 2번 index의 값이 같아야 함\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]), name= \"filter2\")\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1],padding = \"SAME\")\n",
    "print(L2.shape)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2,ksize= [1,1,1,1], strides = [1,1,1,1], padding = \"SAME\")\n",
    "print(L2.shape)\n",
    "# convolution한 결과 : 28 x 28의 원본 이미지 1장이 7 x 7 convolution 된 이미지 64장으로 바뀜\n",
    "\n",
    "# Neural network를 이용하려면 2차원 형태로 변환해줘야 함\n",
    "L2 = tf.reshape(L2, [-1,7*7*64])\n",
    "\n",
    "# 4.Neural Network\n",
    "# 4.1 Weight & bias\n",
    "# shape=[\"컬럼수\",256]\n",
    "W3 = tf.get_Variable(\"weight3\",shape=[7*7*64, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(shape=[256], name = \"bias3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
